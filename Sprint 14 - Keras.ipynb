{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model compilation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAHR\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4929: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 638s 337ms/step - loss: 0.1496 - accuracy: 0.9545 - val_loss: 0.0505 - val_accuracy: 0.9841\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 677s 361ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.0414 - val_accuracy: 0.9867\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 662s 353ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 0.0274 - val_accuracy: 0.9917\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 721s 384ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.0342 - val_accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 761s 406ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0288 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=5, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 42s - loss: 0.0288 - accuracy: 0.9904\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(100))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.nn.sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 16s 236ms/step - loss: 0.7321 - accuracy: 0.6094 - val_loss: 0.5497 - val_accuracy: 0.5625\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 0.4317 - accuracy: 0.8125 - val_loss: 0.3148 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.2792 - accuracy: 0.9375 - val_loss: 0.2090 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.1984 - accuracy: 0.9531 - val_loss: 0.1714 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.1477 - accuracy: 0.9531 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.1050 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9375\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 55ms/step - loss: 0.1167 - accuracy: 0.9375 - val_loss: 0.0924 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.0988 - accuracy: 0.9531 - val_loss: 0.1006 - val_accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.1476 - accuracy: 0.8906 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.0825 - accuracy: 0.9688 - val_loss: 0.0647 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [2.7986765e-03 9.9939585e-01 1.3647377e-03 9.9984735e-01 9.3146831e-01\n",
      " 9.9952519e-01 8.6823225e-02 7.7091044e-01 9.9984884e-01 9.7148490e-01\n",
      " 9.9719864e-01 9.9819273e-01 9.9970561e-01 2.8401256e-02 1.7288327e-04\n",
      " 8.1646442e-04 5.3790319e-01 9.8543569e-05 9.5273107e-01 4.0969253e-04]\n",
      "y_pred [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
      "y_test [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print('y_test', y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.21577921509742737\n",
      "Train accuracy: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problen 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train)\n",
    "y_val_one_hot = enc.transform(y_val)\n",
    "y_test_one_hot = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(4,)))\n",
    "model.add(tf.keras.layers.Dense(100))\n",
    "model.add(tf.keras.layers.Dense(3, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_proba [4.5540985e-10 1.0033697e-03 9.9992871e-01 9.0828083e-09 9.9888748e-01\n",
      " 1.4454493e-11 9.9948895e-01 2.9390227e-04 1.3328160e-04 2.0150731e-03\n",
      " 2.1209560e-07 6.7770260e-04 2.8473118e-04 1.7001365e-04 1.9303027e-04\n",
      " 9.9774808e-01 2.6110321e-04 3.5658391e-04 9.9685991e-01 9.9982327e-01\n",
      " 6.4560396e-08 2.7162622e-04 9.9556869e-01 9.9617189e-01 1.4305311e-05\n",
      " 9.9987161e-01 9.9811989e-01 1.0280719e-03 9.5586181e-03 9.9777716e-01]\n",
      "y_pred [0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1]\n",
      "y_test [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "print('y_test', y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "y_test [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "print(\"y_pred\", y_pred)\n",
    "print('y_test', y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03405049815773964\n",
      "Train accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "x = train[['GrLivArea', 'YearBuilt']]\n",
    "y = train[['SalePrice']]\n",
    "\n",
    "x = np.log(x).values\n",
    "y = np.log(y).values\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit_transform(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(2,)))\n",
    "model.add(tf.keras.layers.Dense(100))\n",
    "model.add(tf.keras.layers.Dense(1, activation = tf.keras.activations.linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 6s 30ms/step - loss: 4.6977 - mse: 4.6977 - val_loss: 0.0729 - val_mse: 0.0729 loss: 4.7678 - mse: 4.76\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0902 - val_mse: 0.0902\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0813 - mse: 0.0813 - val_loss: 0.0733 - val_mse: 0.0733\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0774 - mse: 0.0774 - val_loss: 0.1096 - val_mse: 0.1096A: 0s - loss: 0.0775 - mse: \n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0863 - mse: 0.0863 - val_loss: 0.1205 - val_mse: 0.1205\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 2s 19ms/step - loss: 0.0923 - mse: 0.0923 - val_loss: 0.0708 - val_mse: 0.0708\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 2s 21ms/step - loss: 0.0831 - mse: 0.0831 - val_loss: 0.0733 - val_mse: 0.0733 0s - loss: 0.0707 -\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "              metrics=['mse'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    callbacks=[callback],\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred [12.546217 12.133888 11.900653 12.363333 11.823989]\n",
      "y_test [12.20918779 11.79810441 11.60823564 12.16525065 11.38509209]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = y_pred_proba\n",
    "print(\"y_pred\", y_pred.ravel()[:5])\n",
    "print('y_test', y_test.ravel()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss (test): 0.07019147276878357\n",
      "Mean Squared Error (test): 0.07019147276878357\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss (test):', score[0])\n",
    "print('Mean Squared Error (test):', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation = tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(100))\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 45,360\n",
      "Trainable params: 45,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2400/2400 [==============================] - 64s 18ms/step - loss: 0.2884 - accuracy: 0.9143 - val_loss: 0.2106 - val_accuracy: 0.9369\n",
      "Epoch 2/5\n",
      "2400/2400 [==============================] - 32s 13ms/step - loss: 0.1857 - accuracy: 0.9482 - val_loss: 0.1853 - val_accuracy: 0.9505\n",
      "Epoch 3/5\n",
      "2400/2400 [==============================] - 31s 13ms/step - loss: 0.1554 - accuracy: 0.9550 - val_loss: 0.1733 - val_accuracy: 0.9531\n",
      "Epoch 4/5\n",
      "2400/2400 [==============================] - 40s 16ms/step - loss: 0.1398 - accuracy: 0.9604 - val_loss: 0.1957 - val_accuracy: 0.9503s: 0.1396 \n",
      "Epoch 5/5\n",
      "2400/2400 [==============================] - 36s 15ms/step - loss: 0.1340 - accuracy: 0.9625 - val_loss: 0.1609 - val_accuracy: 0.9599\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    batch_size=20,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, y_val_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred [7 2 1 0 4 1 4 9 6 9]\n",
      "y_test [7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "print(\"y_pred\", y_pred[:10])\n",
    "print('y_test', y_test.ravel()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.16596029698848724\n",
      "Test accuracy: 0.958899974822998\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
